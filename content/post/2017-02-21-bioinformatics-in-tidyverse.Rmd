---
author: "Phil Chapman"
categories: ["R", "tidyverse", "Bioconductor"]
date: 2017-02-21
description: "The power of list-cols in parameterising analyses"
title: "Bioinformatics in the Tidyverse"
---

# Introduction
This is a blog post to expand on a talk I gave at the Manchester R Users Group on 21st February 2017.  In it I give a brief overview of the tidyverse and its core concepts, before going on to discuss how the same concepts can be applied to bioinformatics analysis using Bioconductor classes and packages.

# What is the tidyverse?
The tidyverse is a suite of tools primarily developed by Hadley Wickham LINK and collaborators at RStudio LINK.  The suite of packages can be conveniently installed as follows:

```{r eval=FALSE}
install.packages('tidyverse')
```

There are many talks and resources that go into much greater depth than I do here including:

- Managing many models talk on YouTube by Hadley Wickham LINK
- R for Data Science book LINK
- Tutorials and presentations from RStudio::conf 2017 LINK
- Webinars on RStudio website LINK

# Key concepts in the tidyverse
## Tidy data
They key concept of the tidyverse is that of tidy data.  If you're from a database background then think of this as normalised data.  For example, the table below is NOT tidy data since the year variable is encoded as a column name:

```{r warning=FALSE, message=FALSE}
library(tidyverse)
table4a
```

To turn this into tidy data with one observation per row, we can use the `tidyr` package:

```{r}
df <- gather(table4a, year, cases, -country)
df
```

## Tibbles

Tibbles are an alternative to the data frame.  The key differences are:

- Subsetting a tibble will always produce another tibble.
- A tibble will only print to screen - no more pages of output...

```{r}
dplyr::filter(df, cases == 'Nigeria')
dplyr::select(df, country)
library(gapminder)
gapminder
```

## dplyr and the pipe - %>%

The `dplyr` package provides an intuitive way of manipulating data frames that will come naturally to people from a database background who are used to SQL.  Furthermore, the pipe operator allows function calls to be strung together sequentially rather than nested which improves readability.  For example, the statements below:

```{r}
# base r
gapminder[gapminder$country=='China', c('country', 'continent', 'year', 'lifeExp')]

# dplyr
dplyr::select(dplyr::filter(gapminder, country=='China'), country, continent, year, lifeExp)
```

Give the same output as this:
```{r}
# pipe and dplyr
gapminder %>% dplyr::filter(country=='China') %>% dplyr::select(country, continent, year, lifeExp)
```

The RStudio Data Wrangling cheatsheet LINK provides a useful resource for getting to know dplyr.

## purrr and its map function

The purrr package provides a number of functions to make R more consistent and programming friendly than the equivalent base R functions.  At first it's `map` function seems like a reimplementation of `apply`:

```{r}
map(c(4, 9, 16), sqrt)
```

But `map` will *always* return a list, and there are other members of the `map_` family which will always return a certain data type:

```{r}
map_dbl(c(4, 9, 16), sqrt)
map_chr(c(4, 9, 16), sqrt)
```

## List-cols in data frames

List-cols are a powerful concept that underpin the later part of this tutorial.  If data frames are explained as a way to keep character and number vectors together, then list-cols in tibbles take these a step further and allow lists of any object to be kept together.  For example, we can create nested data frames where we have a data frame within a data frame:

```{r}
gm_nest <- gapminder %>% group_by(country, continent) %>% nest()
gm_nest
```

Since the data column is a list-col we can access it as we would expect from a list.  For example, to get the data for the second row, Albania:

```{r}
gm_nest$data[[2]]
```

## Using map to manipulate list-cols

Since this list column is just a list, we can use map to count the number of rows in each data frame in the list:

```{r}
map_dbl(gm_nest[1:10,]$data, nrow)
```

Rather than providing a ready to use function we can also define our own:

```{r}
map_dbl(gm_nest[1:10,]$data, function(x) nrow(x))
```

There is also a shorthand formula syntax for this where the period `.` represents the element of the list that is being processed:

```{r}
map_dbl(gm_nest[1:10,]$data, ~nrow(.))
```

This allows us to reach into the data frame and perform an operation, such as summarise one of the columns:

```{r}
map_dbl(gm_nest[1:10,]$data, ~round(mean(.$lifeExp),1))
```

Importantly we can also do this at the level of the parent tibble and store the output in the data frame:

```{r}
gm_nest %>% mutate(avg_lifeExp=map_dbl(data, ~round(mean(.$lifeExp),1)))
```

## The power of list-cols

We could have summarised the gapminder data entirely in dplyr without worrying about list-cols and nested data frames:

```{r}
gapminder %>%
    group_by(country) %>%
    summarise(avg_lifeExp=round(mean(lifeExp),1))
```

However, by using `map` rather than `map_dbl` we can create new list-cols, which can contain lists of any object that we want.  In the example below we create a plot for each country, then display the first plot for Afghanistan:

```{r}
gm_plots <- gm_nest %>%
    mutate(plot=map(data, ~qplot(x=year, y=lifeExp, data=.)))
gm_plots
gm_plots$plot[[1]]
```

## A complete example

In this example we combine the approaches described so far to:

1.  Nest the data
2.  Fit a linear regression model for each country
3.  Extract the slope and r2 value for each country
4.  Plot all countries together

```{r}
gapminder_analysis <- gapminder %>%
    group_by(country, continent) %>%
    nest() %>%
    mutate(model=map(data, ~lm(lifeExp ~ year, data=.)),
           slope=map_dbl(model, ~coef(.)['year']),
           r2=map_dbl(model, ~broom::glance(.)$`r.squared`))
gapminder_analysis
ggplot(gapminder_analysis, aes(y=slope, colour=r2, x=continent)) + 
    geom_point(position=position_jitter(w=0.2)) +
    theme_bw()
```

We can see that countries in Asia have has a faster increase in lifespan than those in Europe, whilst for Africa the picture is rather more mixed with some countries increasing and others staying the same or reducing and fitting more poorly to the linear regression model.  Further analysis shows that the reasons for this include genocide and the HIV/AIDS epidemic.

# The tidyverse for Bioinformatics
## What is Bioconductor?

Bioconductor LINK is a suite of R packages and classes developed in R.  This allows biological data to be analysed and stored in efficient and consistent ways.  Analyses such as RNAseq analysis can also be controlled effectively using the list-cols framework.

## A typical RNA-seq workflow

RNA-sequencing is carried out to quantitate the amount of a gene present in a set of samples.  This can be done for all genes in the human genome simulatenously through the power of DNA sequencing.  We then ask which genes are _differentially expressed_ - ie are present in a different abundance in one set of samples (eg from a tumour) than another (eg normal).  A typical RNA-seq experiment will have the following workflow:

- Align and count reads to form a SummarizedExperiment object
- Filter out genes with a low signal
- Specify a design formula to do the differential expression
- Specify a log2 fold change threshold to test for differentially expressed genes
- Plot the results

## An RNA-seq analysis

First load the SummarizedExperiment object and explore it:

```{r warning=FALSE, message=FALSE}
#adapted from https://f1000research.com/articles/4-1070/v2
library(airway)
library(DESeq2)
data(airway)
se <- airway
se
colData(se)
colnames(assay(se))
rownames(assay(se))[1:10]
assay(se)[1:5,1:5]
```

We can count up the number of reads per sample using the `colSums` function, or using `purrr`:
```{r}
colSums(assay(se))
purrr::map_dbl(colnames(assay(se)), ~sum(assay(se)[,.]))
```

We then create a `DESeqDataSet` object and set the design formula
```{r}
dds <- DESeqDataSet(se, design = ~ cell + dex)
```

Get rid of genes with few reads
```{r}
dds <- dds[ rowSums(counts(dds)) > 1, ]
```

Re-count the library size:
```{r}
dds <- estimateSizeFactors(dds)
```

Do a Principal Compnent Analysis to understand the data structure:
```{r}
rld <- vst(dds, blind=FALSE)
pca_plot <- plotPCA(rld, intgroup = c("dex", "cell"))
pca_plot
```

Do the differential expression analysis and extract the results:
```{r}
dds <- DESeq(dds, quiet = TRUE)
res <- results(dds, lfcThreshold=0, tidy = TRUE) %>% tbl_df()
res
```

Plot the results as an MA plot with abundance of the gene on the x-axis and fold change on the y-axis.  Colour represents significance of the statistical test.

```{r}
ma_plot <- ggplot(res, aes(log2(baseMean), log2FoldChange, colour=padj<0.1)) + 
    geom_point(size=rel(0.5), aes(text=row)) + theme_bw()
ma_plot
```

We can look at the top differentially expressed gene to see that there is indeed a difference between treated and untreated:

```{r}
topGene <- res %>% dplyr::arrange(padj) %>% 
    dplyr::slice(1) %>% dplyr::select(row) %>% unlist() %>% unname()
plotCounts(dds, gene=topGene, intgroup=c("dex"))
```

## RNA-seq in the tidyverse

In the workflow there were a number of parameters that we might wish to vary:

- the design formula
- the log2 fold change threshold (`lfcThreshold`)
- the minimum read count

We can set up a control data frame using the `tidyr::crossing` function which contains 1 row per combination of parameters, and then add in the SummarizedExperiment object and a row number:

```{r}
control_df <- tidyr::crossing(formula=c("~ cell + dex", "~ dex"), 
                       lfcThreshold=c(0,1,2),
                       min_count=c(1,5,10))   
control_df <- control_df %>% mutate(rn=row_number(),
                                    se=map(rn, ~se)) %>% dplyr::slice(1:4)
control_df
```

Using `map2` we can execute the `DESeqDataSet` function for each row taking the design formula and SummarizedExperiment object as inputs:

```{r}
results_df <- control_df %>%
    mutate(dds=map2(se, formula, ~DESeqDataSet(.x, design=as.formula(.y))))
results_df
```

At this point it is worth sanity checking that we have done what we wanted to do by comparing the input formula with that extracted from the DESeqDataSet:

```{r}
results_df$formula
map_chr(results_df$dds, ~design(.) %>% as.character() %>% paste(collapse=' '))
```

Then finish off preparing the DESeqDataset object by removing genes below a certain read count:

```{r}
results_df <- results_df %>%
    mutate(dds=map2(dds, min_count, ~.x[ rowSums(counts(.x)) > .y , ]),
           dds=map(dds, estimateSizeFactors))
```

And then doing the differential expression analysis itself and extracting the results:

```{r}
results_df <- results_df %>%
    mutate(dds=map(dds, ~DESeq(., quiet=TRUE, parallel = TRUE)),
           res=map2(dds, lfcThreshold, ~results(.x, lfcThreshold=.y, tidy = TRUE) %>% tbl_df()))
```

## Viewing the results

At this point we can add a plot object to the mix like we did for the gapminder example.  We define a plotting function to make the analysis more readable:

```{r}
#define a plot function
my_plot <- function(df, pthresh) {
    ggplot(df, aes(log2(baseMean), log2FoldChange, colour=padj<pthresh)) + 
        geom_point(size=rel(0.5)) + 
        theme_bw()
}

#make the plots
plots_df <- results_df %>%
    mutate(ma_plot=map2(res, rn, ~my_plot(.x, 0.1) + ggtitle(.y)))
plots_df
```

We can then display the plots from the ma_plot list-col:

```{r}
cowplot::plot_grid(plotlist=plots_df$ma_plot[1:4])
```

Or we can filter the data frame and just show some plots, for example those where the minimum read count was 1:

```{r}
plots_df %>% 
    dplyr::filter(min_count==1) %>% 
    dplyr::select(ma_plot) %>%
    .$ma_plot %>%
    cowplot::plot_grid(plotlist=.)
```

# Limitations

Although the list-col approach  provides useful framework for this type of analysis it does have some limitations:

- All of the data and results has to be held in the memory of one session.
- Can end up with multiple copies of data and very large data frames - models and plots will often contain the same data within the R object.
- Operations on a normal list can be easily parallelised using parallel::parLapply for example.  This is more difficult using the list-col approach although one way is to split the tibble into a list of tibbles, and then parallelise across this.  
- It can also be hard to wrap your brain around the necessary levels of abstraction!

# Conclusion

Storing and manipulating objects in a data frame is a powerful and useful framework for an analysis since it keeps related things together and avoids code repetition and bloat.  Analyses are parameterised which makes it very easy to add new values or change existing onces without copying and pasting big bits of code or having huge complicated functions.  Although in this post it is applied to bioinformatics it could be applied to anything where work is done in specialised R object classes.  

There is lots of work being done in the R community to extend these concepts, so keep an eye out for online presentations and tutorials!!

